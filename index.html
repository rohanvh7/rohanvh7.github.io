<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Rohan Hatagine Resume</title>
  <style>
    @page {
      size: A4;
      margin: 20mm;
    }

    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
    }

    .resume-container {
      width: 210mm;
      min-height: 297mm;
      margin: auto;
      padding: 20mm;
      box-sizing: border-box;
      border: 6px double black;
	  background-color: #fffce6; /* Cream background */
      color: #000; /* Ensure good contrast */
    }

    h1, h2, h3, p, ul {
      margin: 0 0 15px;
    }

    hr {
      border: 1px solid #000;
    }

    ul {
      padding-left: 20px;
    }

    a {
      color: #000;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }
  </style>
</head>
<body>
  <div class="resume-container">
    <h1 style="text-align: center;">Rohan Hatagine</h1>
    <p style="text-align: center;">
      <a href="mailto:email@rohanvh.me">email@rohanvh.me</a> | 
      <a href="https://linkedin.com/in/rohanvh">linkedin.com/in/rohanvh</a>
    </p>

    <h2>Summary</h2>
    <hr />
    <p>
      Data Engineer with 3 years of experience in designing and building robust data pipelines and analytics solutions. Proficient in PySpark, SQL, and Pandas, with a strong foundation in data processing and transformation. Known for excellent problem-solving, research, and collaboration skills. Seeking a challenging role where I can contribute to innovative data-driven projects and continue developing cutting-edge data solutions.
    </p>

    <h2>Technical Skills</h2>
    <hr />
    <p>
      <strong>Programming Languages:</strong> Python, SQL, Bash, Java<br />
      <strong>Libraries:</strong> PySpark, Pandas, OpenPyxl<br />
      <strong>Tools:</strong> Git, Docker, OpsGenie, Postgres, Qlik Replicate, Talend Administration Center, Remedy Suite
    </p>

    <h2>Experience</h2>
    <hr />

    <h3><strong>Data Integration</strong></h3>
    <ul>
      <li>Media project to develop data integration solutions in PySpark, focused on audience measurement. Integrated public demographic and census data to support advanced analytics and enhance media targeting capabilities.</li>
      <li>Designed and developed ETL workflows using PySpark, converting existing Java and Scala Spark implementations. Ensured adherence to standard design patterns and followed the full Software Development Life Cycle (SDLC).</li>
      <li>Worked with small to medium-sized datasets using Pandas for data manipulation, cleaning, and analysis in Python.</li>
      <li>Automated weekly report delivery via email using Python's email package. Generated and formatted Excel reports using OpenPyxl for dynamic data presentation.</li>
      <li>Set up Talend Administration Center and job servers to maintain quick report-generating workflows. Talend setup included SSL setup with automated Venafi pushing, secrets maintenance and extraction using the SafeGuard API.</li>
      <li>Configured Qlik Replicate for on-prem to Google BigQuery data replication jobs, complementing the Talend workflows. Included Postgres setup for audit trail and application stats management.</li>
    </ul>

    <h3><strong>Monitoring Solutions Suite</strong></h3>
    <ul>
      <li>Led the installation and migration of OpsGenie, an alert-routing/on-call management software.</li>
      <li>Developed Bash scripts to monitor clusters for CPU, memory, and disk space utilization during workflow executions and trigger anomalies to OpsGenie using alert-routing.</li>
      <li>Developed a Java client leveraging the OpsGenie Java-based API to migrate old incident, user, and on-call data to the new instance, creating custom workflows for incident management.</li>
      <li>Developed a Python client leveraging the organizationâ€™s Remedy Suite/ITSM workflow API, which supported management of incidents, change requests, tasks, and problem tickets.</li>
    </ul>

    <h2>Certifications</h2>
    <hr />
    <ul>
      <li>Microsoft Fundamentals AZ-900</li>
      <li>AWS Cloud Practitioner</li>
      <li>Databricks Lakehouse Fundamentals</li>
      <li>Cisco Cybersecurity Introduction by Cisco Networking Academy</li>
    </ul>
  </div>
</body>
</html>
