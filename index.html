<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <script defer src="https://cloud.umami.is/script.js" data-website-id="1e5e7931-8957-4cc2-8983-5df41657b494"></script>
  <title>Rohan Hatagine Resume</title>
  <style>
    @page {
      size: A4;
      margin: 20mm;
    }

    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
    }

    .resume-container {
      width: 210mm;
      min-height: 297mm;
      margin: auto;
      padding: 20mm;
      box-sizing: border-box;
      border: 6px double black;
	  background-color: #fffce6; /* Cream background */
      color: #000; /* Ensure good contrast */
    }

    h1, h2, h3, p, ul {
      margin: 0 0 15px;
    }

    hr {
      border: 1px solid #000;
    }

    ul {
      padding-left: 20px;
    }

    a {
      color: #000;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }
  </style>
</head>
<body>
  <div class="resume-container">
    <h1 style="text-align: center;">Rohan Hatagine</h1>
    <p style="text-align: center;">
      <a href="mailto:email@rohanvh.me">email@rohanvh.me</a> | 
      <a href="https://linkedin.com/in/rohanvh">linkedin.com/in/rohanvh</a>
    </p>

    <h2>Summary</h2>
<hr />
<p>
  Data Engineer with 3 years of experience in designing and building robust data pipelines and analytics solutions. Proficient in PySpark, SQL, and Pandas, with a strong foundation in data processing and transformation. Known for excellent problem-solving, research, and collaboration skills. Seeking a challenging role where I can contribute to innovative, data-driven projects and continue developing cutting-edge data solutions.
</p>

<h2>Technical Skills</h2>
<hr />
<p>
  <strong>Programming Languages:</strong> Python, SQL, Bash, Java<br />
  <strong>Libraries:</strong> PySpark, Pandas, OpenPyxl, Beautiful-soup, PyTest<br />
  <strong>Tools:</strong> Git, Docker, OpsGenie, Postgres, Qlik Replicate, Talend Administration Center, Open-LDAP,Jfrog,Remedy Suite
</p>

<h2>Experience</h2>
<hr />

<h3><strong>Data Integration</strong></h3>
<ul>
  <li>Worked in media project to develop data integration solutions in PySpark, focused on audience measurement. Integrated public demographic and census data to support advanced analytics and enhance media targeting capabilities.</li>
  <li>Designed and developed ETL workflows using PySpark, converting existing Java and Scala Spark implementations. Ensured adherence to standard design patterns and followed the full software development life cycle (SDLC).</li>
  <li>Used Pandas for data manipulation, cleaning, and analysis of small to medium-sized datasets.</li>
  <li>Automated weekly report delivery via email using Python's email package. Generated and formatted Excel reports using OpenPyxl for dynamic data presentation.</li>
  <li>Set up Talend Administration Center and job servers to maintain efficient report-generating workflows. The setup included SSL configuration with automated Venafi integration, and secrets management using the SafeGuard API.</li>
  <li>Configured Qlik Replicate for on-premises to Google BigQuery data replication jobs, complementing Talend workflows. Managed Postgres setup for audit trail and application statistics.</li>
  <li>Developed a Python Cliient to scrape SharePoint articles using Microsoft Graph API and BeautifulSoup; cleaned, tagged, and uploaded data to Google Cloud Storage for analysis.</li>
  <li>Developed a Python client to extract account details from LDAP servers using distinguished names, including password expiration info, and generated daily password expiry reports.</li>
</ul>

<h3><strong>Monitoring Solutions Suite</strong></h3>
<ul>
  <li>Led the installation and migration of OpsGenie, an alert-routing and on-call management solution.</li>
  <li>Developed Bash scripts to monitor clusters for CPU, memory, and disk space utilization during workflow executions. Triggered alerts to OpsGenie for anomaly detection.</li>
  <li>Created a Java client using the OpsGenie API to migrate historical incident, user, and on-call data to the new instance, implementing custom workflows for incident management.</li>
  <li>Built a Python client to interface with the organization's Remedy Suite ITSM workflow API for managing incidents, change requests, tasks, and problem tickets.</li>
</ul>

<h2>Certifications</h2>
<hr />
<ul>
  <li>Microsoft Fundamentals AZ-900</li>
  <li>AWS Cloud Practitioner</li>
  <li>Databricks Lakehouse Fundamentals</li>
  <li>Introduction to Cybersecurity â€“ Cisco Networking Academy</li>
</ul>
	</div>
</body>
</html>
