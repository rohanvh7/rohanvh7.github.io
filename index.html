<ul>
<li style="text-align: center;">Rohan Hatagine</li>
</ul>
<p style="text-align: center;">+91-9482070769 | <a href="mailto:email@rohanvh.me">email@rohanvh.me</a> | linkedin.com/in/rohanvh</p>
<h2 style="text-align: left;">Summary</h2>
<hr />
<p>Data Engineer with 3 years of experience in designing and building robust data pipelines and analytics solutions. Proficient in PySpark, SQL, and Pandas, with a strong foundation in data processing and transformation. Known for excellent problem-solving, research, and collaboration skills. Seeking a challenging role where I can contribute to innovative data-driven projects and continue developing cutting-edge data solutions.<br /><br /></p>
<h2>Technical Skills</h2>
<hr />
<p><strong>Programming Languages :&nbsp;</strong>Python , SQL, Bash, Java<br /><br /><strong>Libraries :&nbsp;</strong>PySpark, Pandas,OpenPyxl</p>
<p><strong>Tools : </strong>Git, Docker,OpsGenie, Postgres, Qlik Replicate, Talend Administration Center, Remedy Suite.<strong><br /></strong></p>
<h2><strong><br />Experience</strong></h2>
<hr />
<h3><strong>Data Integration</strong></h3>
<ul>
<li>Media Project to develop data integration solutions in PySpark, focused on audience measurement. Integrated public demographic and census data to support advanced analytics and enhance media targeting capabilities.</li>
<li>Designed and developed ETL workflows using PySpark, converting existing Java and Scala Spark implementations. Ensured adherence to standard design patterns and followed the full Software Development Life Cycle (SDLC)</li>
<li>Worked with small to medium-sized datasets using Pandas for data manipulation, cleaning, and analysis in Python.</li>
<li>Automated weekly report delivery via email using Python's email package. Generated and formatted Excel reports using openpyxl for dynamic data presentation.</li>
<li>Setting up Talend Administartion center and Job servers to maintain quick report generating workflows. Talend setup included SSL setup with automated venafi pushing, Secrets maintaining and extracttion with SafeGuard API.</li>
<li>Setting up Qlik Replicate for on-prem to Google BigQuery data replication jobs, complimented the talend work-flows. Included Postgres setup for audit trail and Application stats management.</li>
</ul>
<h3><strong>Monitoring Solutions Suite</strong></h3>
<ul>
<li>Setting up OpsGenie a alert-routing/on-call management software. Creating Notification workflows that would trigger slack and mail notifications incase production workflow failures. Setting up custom domain for better</li>
<li>Developoed bash scripts that would help monitor clusters for cpu,memory and DiskSpace utilisation during workflow executions and trigger anomalies to OpsGenie with Alert-routing.</li>
<li>Develeoped Java Client , Levraged OpsGenie Java Based API, to Migrate old incident,user, on-call data to new instance, creating custom workflows for incident management.</li>
<li>Developed Python Client for Levraging Organisation's remedy suite / ITSM workflow API , which helped us with Incident, Change Requests,Tasks as well as Problem Ticket Management.<br /><br /></li>
</ul>
<h2>Certifications</h2>
<hr />
<ul>
<li>Microsoft Fundamentals AZ-900</li>
<li>AWS Cloud Practicetioner</li>
<li>Databricks Lakehouse Fundamentals</li>
<li>Cisco Cybersecurity Inroduction by Cisco Networking Academy.&nbsp;</li>
</ul>
<div>&nbsp;</div>
<h2>&nbsp;</h2>